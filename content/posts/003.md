---
title: "OS_FinalExam 筆記"
date: 2022-01-03 T11:04:59+08:00
description: "作業系統期末單元整理."
draft: false
weight: false
aliases: ["/OS_finalExam"]
summary: "OS 作業系統期末 Note"
tags: ["OS", "NOTE"]
categories: ["OS"]
author: "Shu"
# author: ["Me", "You"] # multiple authors
showToc: true
TocOpen: false
hidemeta: false
comments: true
canonicalURL: "https://canonical.url/to/page"
disableHLJS: true # to disable highlightjs
disableShare: false
disableHLJS: false
hideSummary: false
searchHidden: false
ShowReadingTime: true
ShowBreadCrumbs: true
ShowPostNavLinks: true
cover:
    # image: "<image path/url>" # image path/url
    alt: "<alt text>" # alt text
    caption: "<text>" # display caption under cover
    relative: false # when using page bundles set this to true
    hidden: true # only hide on current single page
---

## OS 期末筆記

單元重點

### chap5

- CPU scheduling 目的：最大化 cpu 使用率，主要由 short-term scheduler 負責
- process 之 execution 通常包括 CPU execution(cpu burst time) and I/O wait(i/o burst time)

#### 4種 Cpu scheduling 時機

> **1&4 不能中斷(nonpreemptive) 2&3 可以中斷(preemptive)**
>
> 1. running->waiting (I/O 請求)
> 2. running->ready (time out、interrupt)
> 3. waiting->ready (I/O 完成)  //高優先權變 ready
> 4. process terminates

- nonpreemptive(不可插隊)：若 process 不釋放 CPU 使用權,無法被強迫中斷(自願釋放 CPU)
- preemptive(可插隊)：若 process 不釋放 CPU 使用權,可以被強迫中斷(被迫放棄 CPU)

#### Dispatcher 功能

// def:真正分派 CPU 給 process

> 1. context switching
> 2. 切換至 user mode
> 3. 跳至使用者程式的位置繼續執行

- Dispatch latency(分派延遲)：Dispatchr 結束一個 process，並開始另一個 process 之執行所花的時間(越短越好)

#### cpu scheduling criteria(準則)

1. CPU 使用率(utilization):CPU 越忙越好
2. 產能(Throughput)：單位時間內可完成的 process 數量，越多越好
3. 整體執行時間(Turnaround time)：從 process 進入系統開始至離開系統(完成工作)為止，越短越好 t.t = b.t + w.t
4. 等候時間(Waiting time)：一個 process 在 ready queue 等待取得 CPU 的時間加總，越短越好
5. 回覆時間(Response time)：一個 request 發出後，至第一個回覆收到所花的時間，越短越好

#### CPU scheduling algo

1. FCFS(FIFO)

   **特性:**

   - 排班效能差
   - 平均等待時間長
   - 會遭遇
     - convoy effect(護衛效應)：較短之 cpu time process 必須等較長之 cpu time process 完成工作，導致 cpu 使用率降低，平均等待時間長
     - no starvaion(不飢餓)：低優先權 process 遲遲無法完工，因為無法取得完工所需資源) //有機會完工

2. SJF

   **特性:**

   - 排班效能最佳
   - 可能會 starvation
   - 很難預測下一次 cpu burst time

3. preemptive sjf(SRTF)(shortest remaining time first)
4. RR(Round Robin)

   **特性:**

   - 為 time-sharing 所設計的
   - 類似 FCFS，但加上 preemptive
     任一 process 最多的等候時間將不會超過(n-1)\*q 之時間
     - q 太大=>FCFS
     - q 太小=>context switching 負擔高

5. priority

   **特性:**

   可能會 starvation，用 aging(老化)解決:每隔一段時間，可將系統內等待 process 的優先權提升一級

6. multilevel queue

   - 前景佇列：採 RR (Round Robin)
   - 背景佇列：採 FCFS (First Come First Served)
   - Queue 之間採用:固定優先權強佔排程(Fixed-priority preemptive scheduling)

7. multilevel feedback queue

#### Thread scheduling

- Multiple processor scheduling(多處理器)

  1. 非對稱多處理機系統(Asymmetric multiprocessing):所有排程決定、I/O 處理、及其他系統運作，均由一個處理器(即 master server)掌控，其他處理器只負責執行使用者程式(user code)
  2. 對稱式多處理機系統(Symmetric multiprocessing，SMP):每一個處理器各自排程，所有 process 可置於同一個共用的 ready queue，或每一個處理器有各自的 ready queue

- 對稱式:

  - Processor affinity (親和性) – 保持一個 process 在相同的處理器上執行稱之
  - 軟親和(Soft affinity)：prcoess 有可能轉移
  - 硬親和(Hard affinity)：process 不會有移轉問題

- 在對稱式系統中，負載平衡(load balancing)企圖保持工作均勻的分散在所有處理器。負載平衡的方法：

  1. 推出移轉 (Push migration):週期性檢查每個處理器負載，若發現不平衡，則將過度負載的處理器平均將行程分散到閒置或較不忙的處理器
  2. 引入移轉 (Pull migration):一個閒置或工作較輕的處理器，由忙碌的處理器拉一個正在等候的 process

- real-time sys
  1. 硬性即時系統(hard real-time system)：嚴格限制作業必須在要求的截止期限內完成，絕不可逾期
  2. 軟性即時系統(soft real-time system)：保證高優先權的 Process 必須先於所有低優先權的 Process 完成，但不確保何時進行 scheduling

> 會影響即時系統效能的兩種延遲時間：
>
> 1. 中斷延遲時間(Interrupt latency)：
>    從中斷到達 CPU 至中斷服務常式啟動所需之時間
> 2. 分派延遲時間(Dispatch latency)：
>    排程分派程式結束一行程至開始另一行程所需時間

- 優先權反轉(priority inversion)：高優先權之 process 等待低優先權 process 釋放其所需之資源，但低優先權 process 無法在短時間取得 cpu，造成高優先權 process 等待時間大幅增加。

- 解法:優先權繼承
  讓低優先權 process 先繼承高優先權 process 之權值，讓低優先權 process 取得 cpu 執行，讓高優先權之 process 可取得資源，再回復原本低優先權權值之權值

### chap 6 Synchronization

#### Race condition

多個 process 同時使用共享變數，則可能導致共享變數最終值可能會因為 process 之間的交錯執行而有不同之結果。
·

1. Mutual Exclusion(互斥)：有 process 在 critical section 裡面其他 prcoess 就不可以進去。
2. Progress(前進)：沒有 process 在 critical section 裡面時，而且有 process 想進 critical section，必須在有限時間內決定誰可以進去，不可造成所有 process 都進不去。
3. Bounded Waiting(有限等待)：在一個 process 發出進入 critical section 請求之後，且在該請求被允許之前，其他 process 進入其 critical section 的次數必須有一個限制

#### 軟體  

  1. Peterson 解決方式(2 processes)
  2. Bakery Algorithm(N prcoesses Peterson)

#### 硬體

  1. memory barries:memory 內容改變必須讓 prcoessors 知道
  2. HW instructions:系統直接提供具有 Atomic 特性的指令，讓程式碼可以在單一時間點被完成，且不會中途被插斷。(Atomically Executed:在單位時間內可以順利做完，不受任何中斷干擾)
     1. test-and-set
     2. swap

#### Mutex locks(互斥鎖)(spinlock)

在進入臨界區之前先獲得 Mutex locks，離開臨界區時再釋放 Mutex locks 即可

#### Semaphore(號誌)

  用來解決 C.S. Design 及同歩問題的一種資料型態。

```c
  wait(S) {
      while (S <= 0);
      S--;
  }
  signal(S) {
      S++;
  }
```

### chap 8 Deadlock

#### Deadlock def

系統中存在一組 process 陷入互相等待對方所擁有的資源的情況，造成所有的 process 無法往下執行，使得 CPU 利用度大幅降低。

#### 死結四個必要條件

  > 少一死結不成立

  1. 互斥(Mutual exclusion)：一次只有一個 process 可以使用此資源
  2. 擁有與等待(Hold and wait)：擁有至少一個資源的 process 正在等待獲取其他 process 所擁有的其他資源
  3. 不能強佔(No preemption)：擁有此資源的 process 完成工作後，才自動將此資源釋放出來
  4. 循環等待(Circular wait)：系統中存在一組 processes {P0,P1,…,Pn}，其中 P0 等待 P1 所持有的資源...Pn 等待 P0 所持有的資源，形成循環式等待。

#### 資源分配圖

  > 有圈圈有可能有死結，如果每一種資源型態都只有一個設備，則一定產生死結，複數個設備，則不一定會產生死結。沒圈圈沒有死結

  1. 請求邊(request edge)：有向邊 Pi->Rj 代表 proceess Pi 對資源型態 Rj 的設備發出使用請求
  2. 分配邊(assignment edge)：有向邊 Rj->Pi 代表資源型態 Rj 的一項設備已經分配給 process Pi

#### 死結處理方法

  1. 死結預防(deadlock prevention):讓四個必要條件至少有一個不成立
     - 互斥(Mutual exclusion):但對不可共享的資源則一定成立，通常 read only file 是分享式資源
     - 擁有與等待(Hold and wait):
       - 除非 process 可以一次取得所有工作所需的資源，才允許持有資源
       - process 執行之初可持有部分資源，但要再申請資源前，要先釋放手中所有資源

     - 缺點:資源使用率低、可能發生 starvation
       - 不能強佔(No preemption):讓 process 手上的資源是允許被其它程式搶走的
       - 循環等待(Circular wait):將所有資源型態作一順序性的編號，並要求所有行程依遞增(減)方式來請求資源

  2. 死結避免(deadlock avoidance):
     最簡單及最有用的作法，即要求每一行程提供它所需要的各種資源型態的最大需求量(maximum number)死結避免演算法將動態檢驗資源分配狀態，確保循環等待(circular-wait)的條件不會發生資源分配狀態是由資源的可用量、已分配量、及 process 最大需求量來定義。

     - safe state：
       當程式提出資源的申請時，透過一個叫做「Banker's algorithm」的演算法檢查程式是否會進入「unsafe state」，safe state 是絕對不可能發生 deadlock 的情形，unsafe state 是有可能發生 deadlock 的情形，若允許程式提出資源的申請會進入「unsafe state」，便拒絕該程式的申請。

#### 死結避免演算法

  1. 銀行家演算法 (Banker's algorithm)

     - 資料結構:

       - 可用資源陣列(Available)
       - 最大需求陣列(Max)
       - 已分配陣列(Allocation)
       - 剩餘需求陣列(Need)need = max-allocation

         > 1. request<=need 成立 goto2.
         > 2. request<=available 成立 goto3
         > 3. available = available - request
         >    allocation = allocation + request
         >    need = need - request 成立 goto4

       - 執行 safety algo
         > 新增資料結構:
         > Work
         > Finish
         > 求出一個安全的序列

  2. 資源分配圖形演算法 (Resource-allocation-graph algorithm)
  3. 死結偵測與回復(deadlock detection & recovery)

### chap9 Main Memory

- base 與 limit 暫存器可用來界定 address space

  程式指令、資料與記憶體的位址連結(address binding)(決定 process 執行在 memory 之起始位置)可以發生在 3 個不同的階段：

  1. 編譯時期(Compile time)：如果記憶體的位置是已知，編譯器產生具絕對位址的絕對碼(absolute code)，往後如果位置改變，則程式需重新編譯(recompile)
  2. 載入時期(Load time)：如果記憶體的位置為未知，則編譯器需產生可重定位之程式碼(relocatable code)
  3. 執行時期(Execution time)：若行程在執行期間會從記憶體的某一區段(segment)移至另一區段時，則位址連結將延後至執行時期處理。(base 與 limit 暫存器)

#### 邏輯位址(Logical address)

CPU 所產生的位址稱之，也叫做虛擬位址(virtual address)

#### 實體位址(Physical address)

記憶體單元所看到的位址，真正記憶體的位置(就是載入到記憶體位址暫存器(MAR)之地址)

> 程式執行時虛擬(邏輯)位址與實體位址的 mapping，需藉由記憶體管理單元(Memory-Management Unit，MMU)的硬體來完成

- dynamic loading(動態載入)：常式(routine)通常是在被呼叫時才載入
  - 優點:為了讓記憶體空間做最好的利用
  - 缺點:較不具效率
    (不需要 OS support)
- Dynamic linking(動態鏈結)：類似動態載入，且將鏈結延後至執行時間

  - 優點:也叫 shared library，因為 library 可以共用
    (需要 OS support)

- 先做 linking 再做 loading，所以 loading 前一定會先有 linking。linking 顧名思義就是與其他東西做連結，像是與 library 或者你程式有使用到別的程式的部分。
- Dynamic loading 的目標是“函式沒有用到就不要 load”，Dynamic linking 的目標 則是防止重複 load library。
- 前者未必能防止重複，而後者需要檢查其他 process space，所以需要 OS 才能做到。

- 連續記憶體配置(contiguous allocation):因為 process 載入到 memory 執行，需要一塊連續的 memory space

#### memory protect

- base register 包含最小物理地址的值
- limit register 包含邏輯地址範圍，每個邏輯地址必須小於 limit register

#### memory allocation

- 多重分區 (Multiple-partition)分配:

  - partition:(因為 process 載入到 memory 執行，需要一塊連續的 memory space)，即是 process 數目
  - partition size:也稱 varaiable partition，因為每個 process 大小不同
  - hole:process 多次的配置與釋放後，會有一些空間 free

- 如何從 list of free holes 找出滿足記憶體大小需求為 n 的請求?

  1. First-fit:分配第一個夠大的 hole 給 process
  2. Best-fit:在足夠大的 hole 裡面找出最小的 hole
  3. Worst-fit:在足夠大的 hole 給他最大的 hole
     1 ,2 > 3
     但連續記憶體配置會遭遇一個問題：External Fragmentation

#### Fragmentation(碎裂)

1. External Fragmentation(外部碎裂):memory space 加起來夠大，但卻不連續，導致無法分配
2. Internal Fragmentation(內部碎裂):分配的 memory space 比實際需求還大所造成的浪費，且這些空間不能再被使用

- 解決外碎

  1. compation(壓縮)
  2. paging(分頁)

#### paging

  1. 對實體位址空間採用非連續性配置
  2. 解決外碎，但還是有內碎

#### page table 太大或建構方法

  1. Multilevel paging
  2. Hashing Page Table
  3. Invert Page Table

### chap 10 Virtual Memory

#### VM

一種允許行程執行時，不須完全載入記憶體的做法

  > 優點：程式可以大於實體記憶體
  > logical address space 可以大過 physical address space
  > 缺點:不容易實作，可能會降低效能

  1. 邏輯位址空間可以遠大於實體記憶體空間
  2. multiprogramming degree 增加
  3. I/O time 減少

#### 實作 VM

  1. 需求分頁(Demand paging)：於實際需要時才載入 pages

     - 在分頁表中每一項目均有一個有效/無效位元(valid/invalid bit)
       (v 表分頁在記憶體內，i 表分頁不在記憶體內)
     - 當分頁不在記憶體內時(bit = i)，發生 page fault

  2. 需求分段(Demand segmentation)：於實際需要時才載入 segmentation

#### page fault handling

  1. 決定是否為合法/非法的記憶體存取
  2. 非法:終止這個 process，合法:page 不再記憶體
  3. 尋找可用頁框(free frame)
  4. 讀取 page 到可用頁框
  5. 修改 page table
  6. 重新執行導致 page fault 的指令

#### 分頁有效存取時間 (Effective Access Time) 之計算

  > EAT = (1-p) _Memory Access Time + p_ (Page fault process time)
  > p 是 page fault ratio.
  > 例:
  > page fault ratio = 20%，
  > Memory Access Time=100ns,
  > Page fault process time = 5ns
  > =>(1-0.2)*100 + 0.2*5 = 9

#### page replacement algo

  1. FIFO
  2. OPT
  3. LRU

- Belady's anomaly：分配給 process 的頁框數增加，理應 page fault 次數應該降低，但 page fault ratio 卻不減反升

#### Thrashing(振盪)

當 CPU 效能低時，系統會想引入更多的 process 讓 CPU 盡可能地工作(multiprogramming degree)。但當存有太多 process 時，大部分的工作將會花費在 page fault 造成的 Page Replacement，致使 CPU 效率下降，最後造成 CPU 的效能越來越低。

- 方法
  1. 降低 Multiprogramming Degree。
  2. 利用 Page Fault Frequency (Ratio) 控制來防止 Thrashing。
  3. 利用 Working Set Model 預估各 Process 在不同執行時期所需的頁框數，並依此提供足夠的頁框數，以防止 Thrashing。

#### copy-on-write

OS 會配置一個 new frame 給 child，將 page 內容 copy 一份到 new frame，修改 child 之 page table 指向 new frame 後，child 才進行 write 動作。

- 優點：減少記憶體占用、增加 process 的 creation 速度
